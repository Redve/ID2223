{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeableNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: geopy in c:\\users\\adnane\\appdata\\roaming\\python\\python310\\site-packages (2.4.1)\n",
      "Requirement already satisfied: geographiclib<3,>=1.52 in c:\\users\\adnane\\appdata\\roaming\\python\\python310\\site-packages (from geopy) (2.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'DOSKEY' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\program files\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\program files\\python310\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import ensemble, tree, linear_model\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%pip install geopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load mean and variance csv files\n",
    "mean_df = pd.read_csv('C:/Users/Adnane/OneDrive - Delft University of Technology/Bureaublad/TransformedDataframes/mean.csv')\n",
    "var_df = pd.read_csv('C:/Users/Adnane/OneDrive - Delft University of Technology/Bureaublad/TransformedDataframes/var.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_example = pd.read_csv('C:/Users/Adnane/OneDrive - Delft University of Technology/Bureaublad/TransformedDataframes/row_example.csv')\n",
    "len(row_example.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('C:/Users/Adnane/OneDrive - Delft University of Technology/Bureaublad/TransformedDataframes/X_train.csv')\n",
    "X_test = pd.read_csv('C:/Users/Adnane/OneDrive - Delft University of Technology/Bureaublad/TransformedDataframes/X_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.90282435  0.76017419  0.0213333  ...  0.89711484 -0.59530663\n",
      "  -0.42818737]\n",
      " [-1.64675526 -1.28410622 -1.07531847 ... -1.20905876 -0.1315592\n",
      "  -0.42818737]\n",
      " [ 0.90282435  0.76017419  1.11798508 ...  0.92309098 -0.34677945\n",
      "  -0.42818737]\n",
      " ...\n",
      " [ 0.90282435  0.76017419  0.56965919 ...  0.61579022 -0.34273124\n",
      "  -0.42818737]\n",
      " [-1.64675526 -1.96553302 -1.07531847 ... -1.17897056 -1.51557561\n",
      "  -0.42818737]\n",
      " [-0.55407828 -1.28410622 -0.52699259 ... -0.70899297 -0.0501847\n",
      "   2.33542617]]\n",
      "[[-1.03928459  0.13870615  1.37778996 ...  0.56532876 -0.22750898\n",
      "   0.47741795]\n",
      " [ 2.87066376 -1.95689002 -0.3871258  ... -0.16583938  0.20309491\n",
      "   0.34060038]\n",
      " [-1.99908544  0.51454624  1.03113474 ... -0.37215776  0.02880952\n",
      "  -0.25073506]\n",
      " ...\n",
      " [-1.75330445  0.91574922  0.51241095 ... -0.02674048  0.1127157\n",
      "  -0.33667481]\n",
      " [ 1.90182558 -2.16460583 -1.50408343 ...  0.04588324  0.33134316\n",
      "   0.35711714]\n",
      " [ 2.39433367  0.95203066  0.01069371 ... -1.43609588 -1.18092766\n",
      "   0.07326813]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "scaler = StandardScaler()\n",
    "# Fit on training set only.\n",
    "scaler.fit(X_train)\n",
    "# Apply transform to both the training set and the test set.\n",
    "X_train = scaler.transform(X_train)\n",
    "print(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "pca = PCA(.95)\n",
    "pca.fit(X_train)\n",
    "X_train = pca.transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_example = scaler.transform(row_example)\n",
    "row_example = pca.transform(row_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.24425832 -0.55898086  0.85305421 -1.21416419 -0.29532092  0.01592601\n",
      "   0.81078824 -0.32508693  1.9225066  -0.17313309 -0.98319712  0.44631827\n",
      "  -0.04358869  0.80931291]]\n"
     ]
    }
   ],
   "source": [
    "print(row_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "# import pickle\n",
    "# import numpy as np\n",
    "# scaler = StandardScaler()\n",
    "# #convert dataframe to array()\n",
    "# scaler.mean_ = mean_df.T\n",
    "# scaler.scale_ = var_df.T\n",
    "# filename = 'C:/Users/Adnane/OneDrive - Delft University of Technology/Bureaublad/TransformedDataframes/pca_model.sav'\n",
    "# pca = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "# #apply scaler and pca to row_example\n",
    "# row_example_scaled = scaler.transform(row_example)\n",
    "# row_example_pca = pca.transform(row_example_scaled)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = pd.read_csv('C:/Users/Adnane/OneDrive - Delft University of Technology/Bureaublad/TransformedDataframes/X_train.csv')\n",
    "# #apply scaler and pca to X_train\n",
    "# X_train_scaled = scaler.transform(X_train)\n",
    "# print(X_train_scaled)\n",
    "# X_train_pca = pca.transform(X_train_scaled)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the keras_model.h5 file\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "model = keras.models.load_model('C:/Users/Adnane/OneDrive - Delft University of Technology/Bureaublad/TransformedDataframes/best_model1.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 196ms/step\n",
      "[[2.2626698]]\n"
     ]
    }
   ],
   "source": [
    "#make predictions on the row_example_pca\n",
    "predictions = model.predict(row_example)\n",
    "print(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
